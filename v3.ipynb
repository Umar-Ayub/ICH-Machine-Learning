{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import roc_auc_score, precision_score, recall_score, f1_score\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, StackingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.decomposition import PCA\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from boruta import BorutaPy\n",
    "import os\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from joblib import dump, load\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct_imbalance(X, y, method='SMOTE'):\n",
    "    if method == 'SMOTE':\n",
    "        resampler = SMOTE(random_state=42)\n",
    "    elif method == 'undersampling':\n",
    "        resampler = RandomUnderSampler(random_state=42)\n",
    "    X_res, y_res = resampler.fit_resample(X, y)\n",
    "    return X_res, y_res\n",
    "\n",
    "def apply_boruta(X, y, max_depth=5, n_estimators='auto', random_state=42):\n",
    "    rf = RandomForestClassifier(n_jobs=-1, class_weight='balanced', max_depth=max_depth, random_state=random_state)\n",
    "    boruta_selector = BorutaPy(rf, n_estimators=n_estimators, random_state=random_state)\n",
    "    boruta_selector.fit(X.values, y.values)\n",
    "    selected_features = X.columns[boruta_selector.support_].tolist()\n",
    "    X_reduced = X.loc[:, selected_features]\n",
    "    return X_reduced\n",
    "\n",
    "\n",
    "def apply_pca(X, n_components=0.95):\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    pca = PCA(n_components=n_components)\n",
    "    X_reduced = pca.fit_transform(X_scaled)\n",
    "    return X_reduced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../ich_data_w_scores_modified.csv')\n",
    "\n",
    "# Drop specified score columns and reset index\n",
    "score_cols = [\"oICH_score\", \"mICH_score\", \"ICH_GS_score\", \"LSICH_score\", \"ICH_FOS_score\", \"Max_ICH_score\"]\n",
    "df = df.drop(columns=score_cols).reset_index(drop=True)\n",
    "\n",
    "# Features and targets\n",
    "X = df.drop(columns=['MORT90', 'MRS90'])\n",
    "y_mort90 = df['MORT90']\n",
    "y_mrs90 = df['MRS90'].apply(lambda x: 0 if x <= 3 else 1)  # Binarizing MRS90\n",
    "\n",
    "# Splitting the dataset into training and temporary test sets\n",
    "X_train, X_test, y_train_mort90, y_test_mort90 = train_test_split(X, y_mort90, test_size=0.2, random_state=42)\n",
    "X_train, X_test, y_train_mrs90, y_test_mrs90 = train_test_split(X, y_mrs90, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply SMOTE and undersampling after splitting, only to training data\n",
    "X_train_mort90_smote, y_train_mort90_smote = correct_imbalance(X_train, y_train_mort90, method='SMOTE')\n",
    "X_train_mrs90_smote, y_train_mrs90_smote = correct_imbalance(X_train, y_train_mrs90, method='SMOTE')\n",
    "X_train_mort90_undersample, y_train_mort90_undersample = correct_imbalance(X_train, y_train_mort90, method='undersampling')\n",
    "X_train_mrs90_undersample, y_train_mrs90_undersample = correct_imbalance(X_train, y_train_mrs90, method='undersampling')\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "pca = PCA(n_components=0.95, random_state=42)\n",
    "X_train_pca = pca.fit_transform(X_train_scaled)\n",
    "X_test_pca = pca.transform(X_test_scaled)\n",
    "\n",
    "# Example of applying Boruta\n",
    "rf = RandomForestClassifier(n_jobs=-1, max_depth=5, random_state=42)\n",
    "boruta = BorutaPy(rf, n_estimators='auto', verbose=0, random_state=42)\n",
    "boruta.fit(X_train_scaled, y_train_mort90)\n",
    "X_train_boruta = boruta.transform(X_train_scaled)\n",
    "X_test_boruta = boruta.transform(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = {\n",
    "    \"Original mort90\": (X_train, y_train_mort90, X_test, y_test_mort90),\n",
    "    \"SMOTE mort90\": (X_train_mort90_smote, y_train_mort90_smote,  X_test, y_test_mort90),\n",
    "    \"Undersampled mort90\": (X_train_mort90_undersample, y_train_mort90_undersample,  X_test, y_test_mort90),\n",
    "    \"Boruta mort90\": (X_train_boruta, y_train_mort90,  X_test_boruta, y_test_mort90),\n",
    "    \"PCA mort90\": (X_train_pca, y_train_mort90,  X_test_pca, y_test_mort90),\n",
    "    \"Original mrs90\": (X_train, y_train_mrs90, X_test, y_test_mrs90),\n",
    "    \"SMOTE mrs90\": (X_train_mrs90_smote, y_train_mrs90_smote, X_test, y_test_mrs90),\n",
    "    \"Undersampled mrs90\": (X_train_mrs90_undersample, y_train_mrs90_undersample,X_test, y_test_mrs90),\n",
    "    \"Boruta mrs90\": (X_train_boruta, y_train_mrs90, X_test_boruta, y_test_mrs90),\n",
    "    \"PCA mrs90\": (X_train_pca, y_train_mrs90, X_test_pca, y_test_mrs90)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_and_evaluate_model(model, param_grid, datasets, model_name, results_df_path):\n",
    "    # Ensure models directory exists\n",
    "    if not os.path.exists('models'):\n",
    "        os.makedirs('models')\n",
    "        \n",
    "    # Initialize or load results DataFrame\n",
    "    try:\n",
    "        results_df = pd.read_csv(results_df_path)\n",
    "    except FileNotFoundError:\n",
    "        results_columns = ['Target', 'Dataset', 'Model', 'Best Params', 'Test AUC', 'Precision', 'Recall', 'F1']\n",
    "        results_df = pd.DataFrame(columns=results_columns)\n",
    "\n",
    "    for name, (X_train, y_train, X_test, y_test) in datasets.items():\n",
    "        grid_search = GridSearchCV(model, param_grid, cv=5, scoring='roc_auc')\n",
    "        grid_search.fit(X_train, y_train)\n",
    "\n",
    "        # Save the best model\n",
    "        best_model = grid_search.best_estimator_\n",
    "        y_test_pred = best_model.predict_proba(X_test)[:, 1]\n",
    "        y_pred = (y_test_pred >= 0.5).astype(int)\n",
    "        auc_test = roc_auc_score(y_test, y_test_pred)\n",
    "        precision = precision_score(y_test, y_pred)\n",
    "        recall = recall_score(y_test, y_pred)\n",
    "        f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "        sanitized_name = name.replace(\" \", \"_\")\n",
    "        model_filename = f\"models/{model_name}_{sanitized_name}.joblib\"\n",
    "        dump(best_model, model_filename)\n",
    "\n",
    "        # Prepare a DataFrame row for the current results\n",
    "        new_row = pd.DataFrame({\n",
    "            'Target': ['mrs90' if 'mrs90' in name else 'mort90'],\n",
    "            'Dataset': [name],\n",
    "            'Model': [model_name],\n",
    "            'Best Params': [str(grid_search.best_params_)],\n",
    "            'Test AUC': [auc_test],\n",
    "            'Precision': [precision],\n",
    "            'Recall': [recall],\n",
    "            'F1': [f1]\n",
    "        })\n",
    "\n",
    "        # Concatenate the new row to the results DataFrame\n",
    "        results_df = pd.concat([results_df, new_row], ignore_index=True)\n",
    "\n",
    "    # Save updated results DataFrame\n",
    "    results_df.to_csv(results_df_path, index=False)\n",
    "    return results_df\n",
    "\n",
    "# # Define parameter grids for each model\n",
    "# param_grids = {\n",
    "#     'LogisticRegression': {'C': [0.01, 0.1, 1], 'solver': ['liblinear', 'lbfgs']},\n",
    "#     'RandomForest': {'n_estimators': [100, 200, 300], 'max_depth': [3, 5, 10]}\n",
    "# }\n",
    "\n",
    "# Define parameter grids for each model\n",
    "param_grids = {\n",
    "    # 'LogisticRegression': {'C': [0.01, 0.1, 1], 'solver': ['liblinear', 'lbfgs']},\n",
    "    'XGBoost': {'n_estimators': [100, 200, 300], 'max_depth': [3, 5, 10], 'learning_rate': [0.01, 0.1, 0.3]},\n",
    "    'MLP': {'hidden_layer_sizes': [(50,), (100,), (50, 50)], 'activation': ['tanh', 'relu'], 'solver': ['sgd', 'adam'], 'alpha': [0.0001, 0.001, 0.01], 'learning_rate': ['constant', 'adaptive']},\n",
    "    # 'RandomForest': {'n_estimators': [100, 200, 300], 'max_depth': [3, 5, 10]}\n",
    "}\n",
    "\n",
    "models = {\n",
    "    # 'LogisticRegression': LogisticRegression(max_iter=1000),\n",
    "    'XGBoost': XGBClassifier(use_label_encoder=False, eval_metric='logloss'),\n",
    "    'MLP': MLPClassifier(max_iter=1000),\n",
    "    # 'RandomForest': RandomForestClassifier()\n",
    "}\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    results_df_path = f\"{model_name.lower()}_results.csv\"\n",
    "    run_and_evaluate_model(model, param_grids[model_name], datasets, model_name, results_df_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'estimator'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 19\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m model_name, model \u001b[38;5;129;01min\u001b[39;00m models\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m     18\u001b[0m     results_df_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_name\u001b[38;5;241m.\u001b[39mlower()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_results.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 19\u001b[0m     \u001b[43mrun_and_evaluate_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparam_grids\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatasets\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresults_df_path\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[9], line 18\u001b[0m, in \u001b[0;36mrun_and_evaluate_model\u001b[0;34m(model, param_grid, datasets, model_name, results_df_path)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# Process each set of parameters tested in the grid search\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, params \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(grid_search\u001b[38;5;241m.\u001b[39mcv_results_[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mparams\u001b[39m\u001b[38;5;124m'\u001b[39m]):\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;66;03m# Retrieve the model trained with current parameters\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m     current_model \u001b[38;5;241m=\u001b[39m grid_search\u001b[38;5;241m.\u001b[39mbest_estimator_ \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m==\u001b[39m grid_search\u001b[38;5;241m.\u001b[39mbest_index_ \u001b[38;5;28;01melse\u001b[39;00m \u001b[43mgrid_search\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcv_results_\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mestimator\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m[i]\n\u001b[1;32m     19\u001b[0m     y_test_pred \u001b[38;5;241m=\u001b[39m current_model\u001b[38;5;241m.\u001b[39mpredict_proba(X_test)[:, \u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m     20\u001b[0m     y_pred \u001b[38;5;241m=\u001b[39m (y_test_pred \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.5\u001b[39m)\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mint\u001b[39m)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'estimator'"
     ]
    }
   ],
   "source": [
    "\n",
    "# # Define parameter grids for each model\n",
    "# param_grids = {\n",
    "#     'LogisticRegression': {'C': [0.01, 0.1, 1], 'solver': ['liblinear', 'lbfgs']},\n",
    "#     # 'XGBoost': {'n_estimators': [100, 200, 300], 'max_depth': [3, 5, 10], 'learning_rate': [0.01, 0.1, 0.3]},\n",
    "#     # 'MLP': {'hidden_layer_sizes': [(50,), (100,), (50, 50)], 'activation': ['tanh', 'relu'], 'solver': ['sgd', 'adam'], 'alpha': [0.0001, 0.001, 0.01], 'learning_rate': ['constant', 'adaptive']},\n",
    "#     'RandomForest': {'n_estimators': [100, 200, 300], 'max_depth': [3, 5, 10]}\n",
    "# }\n",
    "\n",
    "# models = {\n",
    "#     'LogisticRegression': LogisticRegression(max_iter=1000),\n",
    "#     # 'XGBoost': XGBClassifier(use_label_encoder=False, eval_metric='logloss'),\n",
    "#     # 'MLP': MLPClassifier(max_iter=1000),\n",
    "#     'RandomForest': RandomForestClassifier()\n",
    "# }\n",
    "\n",
    "# # Assuming 'datasets' is defined correctly elsewhere\n",
    "# for model_name, model in models.items():\n",
    "#     results_df_path = f\"{model_name.lower()}_results.csv\"\n",
    "#     run_and_evaluate_model(model, param_grids[model_name], datasets, model_name, results_df_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ohm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
